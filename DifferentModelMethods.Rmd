---
title: "DifferentModelMethod"
author: "Hoang Le Xuan"
date: "2024-04-06"
output: html_document
---

Reference:https://rspatial.org/

## Model Methods
```{r}
library(dismo)
library(maptools)

#Uncomment if you wanna downlaod these packages
#install.packages("e1071")
#install.packages('caret', dependencies = TRUE)
library(e1071)


data(wrld_simpl)
predictors <- stack(list.files(path="data/bioclim",  pattern='asc',  full.names=TRUE ))

canetoad <- read.table("data/ctsel.csv", header = T, sep=',')
canetoad <- canetoad[,-1]
presvals <- extract(predictors, canetoad)

set.seed(0)
backgr <- randomPoints(predictors, 500)
absvals <- extract(predictors, backgr)
pb <- c(rep(1, nrow(presvals)), rep(0, nrow(absvals)))
sdmdata <- data.frame(cbind(pb, rbind(presvals, absvals)))

```

```{r}
save(presvals, file = "presvalsDMM.RData")
load("presvalsDMM.RData")
```


Make training and testing set
```{r}

set.seed(0)
group <- kfold(canetoad, 5)
pres_train <- canetoad[group != 1, ]
pres_test <- canetoad[group == 1, ]

pres_train

```

We will look into part of the world map that is Australia. This is the areas not native for the cane toad species.
```{r}
ext <- extent(113, 153, -43, -10)

```
The first layer in the RasterStack is used as a ‘mask’. That ensures that random points only occur within the spatial extent of the rasters, and within cells that are not NA, and that there is only a single absence point per cell. Here we further restrict the background points to be within 12.5% of our specified extent ‘ext’.

The background points are divided into training and testing sets using a k-fold method (here, 5-fold). This means the data is divided into five groups; four groups are used for training (80% of the data), and one group is used for testing (20% of the data). This split is facilitated by assigning a group number to each point and then selecting points for training and testing based on these group assignments (group != 1 for training and group == 1 for testing). 

```{r}
set.seed(10)
#generate random relate point
backg <- randomPoints(predictors, n=1000, ext=ext, extf = 1.25) # (extent factor, here 1.25, meaning the extent is increased by 25%
colnames(backg) = c('lon', 'lat')

#k-fold method (here, 5-fold)
group <- kfold(backg, 5)

#splitting trainign and testing
backg_train <- backg[group != 1, ]
backg_test <- backg[group == 1, ]
```


```{r}
#create raster object from first layer of predictors
r <- raster(predictors, 1)

#raster plotting. plots the raster, but instead of showing the actual values, it displays whether each cell is NA (missing data) or not. Cells that are not NA are shown in light grey, and cells that are NA are shown in white. The legend=FALSE parameter hides the legend for this plot.
plot(!is.na(r), col=c('white', 'light grey'), legend=FALSE)

#highlight area interest in studying
plot(ext, add=TRUE, col='red', lwd=2)

#This adds the background (absence) points used for training the model to the plot. They are represented by yellow dashes (pch='-'), with a size specified by cex=0.5.
points(backg_train, pch='-', cex=0.5, col='yellow')
points(backg_test, pch='-',  cex=0.5, col='black')# background (absence) points used for testing the model.
points(pres_train, pch= '+', col='green') #presence points for training
points(pres_test, pch='+', col='blue') ##presence points for testing
```
## Profile methods
  
The three methods described here, Bioclim, Domain, and Mahal. These methods are implemented in the dismo package, and the procedures to use these models are the same for all three.

### BIOCLIM
Bioclim model using data.frame with each row representing the environmental data at known sites of presence of a species. Here we fit a bioclim model simply using the predictors and the occurrence points (the function will do the extracting for us).

```{r}
bc <- bioclim(predictors, pres_train)
?bioclim
plot(bc, a=1, b=2, p=0.85)
```
We evaluate the model in a similar way, by providing presence and background (absence) points, the model, and a RasterStack:

```{r}
e <- evaluate(pres_test, backg_test, bc, predictors)
e

#class          : ModelEvaluation 
#n presences    : 168 
#n absences     : 200 
#AUC            : 0.7201786. It means the model has a 72% chance of correctly distinguishing between presence and absence sites.
#cor            : 0.3286274. correlation between observed values and predicted values
#max TPR+TNR at : 0.02788233. The max TPR+TNR at a very low value suggests that the best cutoff for classifying presences and absences is quite low, which could be due to the data distribution or the particularities of the model.

#Look for this threshold
tr <- threshold(e, 'spec_sens')
tr
## [1] 0.02788233

```


And we use the RasterStack with predictor variables to make a prediction to a RasterLayer
(RasterStack a collection of RasterLayer objects with the same spatial extent and resolution):

```{r}
pb <- predict(predictors, bc, ext=ext, progress='')
pb
## class      : RasterLayer
## dimensions : 112, 116, 12992  (nrow, ncol, ncell)
## resolution : 0.5, 0.5  (x, y)
## extent     : -90, -32, -33, 23  (xmin, xmax, ymin, ymax)
## crs        : +proj=longlat +datum=WGS84 +no_defs
## source     : memory
## names      : layer
## values     : 0, 0.7096774  (min, max)
par(mfrow=c(1,2))
plot(pb, main='Bioclim, raw values')
plot(wrld_simpl, add=TRUE, border='dark grey')
plot(pb > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')

```

### Domain
Below we fit a domain model, evaluate it, and make a prediction. We map the prediction, as well as a map subjectively classified into presence / absence.

```{r}
dm <- domain(predictors, pres_train)
e <- evaluate(pres_test, backg_test, dm, predictors)
e
## class          : ModelEvaluation
## n presences    : 23
## n absences     : 200
## AUC            : 0.7097826
## cor            : 0.2138087
## max TPR+TNR at : 0.7107224
pd = predict(predictors, dm, ext=ext, progress='')
par(mfrow=c(1,2))
plot(pd, main='Domain, raw values')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(e, 'spec_sens')
plot(pd > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
```
## Mahalanobis distance

```{r}
which(is.na(predictors), arr.ind=TRUE)
typeof(predictors)
colnames(predictors)
```


```{r}
mm <- mahal(predictors, pres_train)
e <- evaluate(pres_test, backg_test, mm, predictors)
e
## class          : ModelEvaluation
## n presences    : 23
## n absences     : 200
## AUC            : 0.7686957
## cor            : 0.1506777
## max TPR+TNR at : 0.1116504
pm = predict(predictors, mm, ext=ext, progress='')
par(mfrow=c(1,2))
pm[pm < -10] <- -10
plot(pm, main='Mahalanobis distance')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(e, 'spec_sens')
plot(pm > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
```
## Classical regression models

```{r}
train <- rbind(pres_train, backg_train)
pb_train <- c(rep(1, nrow(pres_train)), rep(0, nrow(backg_train)))
envtrain <- extract(predictors, train)
envtrain

extent(predictors)

envtrain <- data.frame( cbind(pa=pb_train, envtrain) )
#envtrain[,'biome'] = factor(envtrain[,'biome'], levels=1:14)
head(envtrain)
##   pa bio1 bio12 bio16 bio17 bio5 bio6 bio7 bio8 biome
## 1  1  263  1639   724    62  338  191  147  261     1
## 2  1  263  1639   724    62  338  191  147  261     1
## 3  1  253  3624  1547   373  329  150  179  271     1
## 4  1  243  1693   775   186  318  150  168  264     1
## 5  1  252  2501  1081   280  326  154  172  270     1
## 6  1  240  1214   516   146  317  150  168  261     2
testpres <- data.frame( extract(predictors, pres_test) )
testbackg <- data.frame( extract(predictors, backg_test) )

```
```{r}
# logistic regression:
gm1 <- glm(pa ~ bclim12 +bclim15 +bclim16 +bclim2 +bclim3 +bclim5 +bclim8 +bclim6,
            family = binomial(link = "logit"), data=envtrain)

summary(gm1)
```

outside of reading, checking if raster outside the range

```{r}
library(raster)
library(sp)

# Assuming your 'train' data frame is structured like the one in the image you provided
coordinates(train) <- ~lon+lat

# Now set the CRS for 'train' to match the CRS of the predictors raster
# (Replace the EPSG code with the actual code for your predictors raster)
crs(train) <- crs(predictors)

head(data.frame(coordinates(train)))
```

check if range is outside reach
```{r}
# Get the extent of the raster
raster_extent <- extent(predictors)

# Check if each point is within the raster extent
inside <- apply(coordinates(train), 1, function(point) {
  raster_extent@xmin <= point[1] && point[1] <= raster_extent@xmax &&
  raster_extent@ymin <= point[2] && point[2] <= raster_extent@ymax
})

# 'inside' will be a logical vector indicating whether each point is inside the raster extent

```





## Generalized Linear Models

```{r}
gm1 <- glm(pa ~ .,
            family = binomial(link = "logit"), data=envtrain)
summary(gm1)
```

```{r}
coef(gm1)

envtrain

```


[Modify this]
```{r}
gm2 <- glm(pa ~ bclim1 + bclim5 + bclim6 + bclim7 + bclim8 + bclim12 + bclim16 + bclim17,
            family = gaussian(link = "identity"), data=envtrain)
ge1 <- evaluate(testpres, testbackg, gm1)
ge1
```


```{r}
ge2 <- evaluate(testpres, testbackg, gm2)
ge2
```



```{r}
ext <- extent(-90, -32, -33, 23)
#ext <- extent(-180, 180, 0, 0)

```


```{r}
pg <- predict(predictors, gm2, ext=ext)
par(mfrow=c(1,2))
plot(pg, main='GLM/gaussian, raw values')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(ge2, 'spec_sens')
plot(pg > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
points(backg_train, pch='-', cex=0.25)
```
## Generalized Additive Models

# Machine learning methods
Methods include Artifical Neural Networks (ANN), Random Forests, Boosted Regression Trees, and Support Vector Machines.

MaxEnt (short for “Maximum Entropy”; Phillips et al., 2006) is the most widely used SDM algorithm.

```{r}
maxent()
## Loading required namespace: rJava
## This is MaxEnt version 3.4.3
xm <- maxent(predictors, pres_train, factors='biome')
## This is MaxEnt version 3.4.3
plot(xm)
```
A response plot:
```{r}
response(xm)

```

```{r}
e <- evaluate(pres_test, backg_test, xm, predictors)
e
## class          : ModelEvaluation
## n presences    : 23
## n absences     : 200
## AUC            : 0.8336957
## cor            : 0.3789954
## max TPR+TNR at : 0.1772358
px <- predict(predictors, xm, ext=ext, progress='')
par(mfrow=c(1,2))
plot(px, main='Maxent, raw values')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(e, 'spec_sens')
plot(px > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
```
### Boosted Regression Trees
### Random Forest
 rf1 does regression, rf2 and rf3 do classification (they are exactly the same models). See the function tuneRF for optimizing the model fitting procedure.
 
```{r}
library(randomForest)
model <- pa ~ bio1 + bio5 + bio6 + bio7 + bio8 + bio12 + bio16 + bio17
rf1 <- randomForest(model, data=envtrain)

model <- factor(pa) ~ bio1 + bio5 + bio6 + bio7 + bio8 + bio12 + bio16 + bio17
rf2 <- randomForest(model, data=envtrain)
rf3 <- randomForest(envtrain[,1:8], factor(pb_train))
erf <- evaluate(testpres, testbackg, rf1)
erf
```

```{r}
pr <- predict(predictors, rf1, ext=ext)
par(mfrow=c(1,2))
plot(pr, main='Random Forest, regression')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(erf, 'spec_sens')
plot(pr > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
points(backg_train, pch='-', cex=0.25)

```
### Support Vector Machines

unction ‘ksvm’ in package ‘kernlab’ and the ‘svm’ function in package ‘e1071’. ‘ksvm’ includes many different SVM formulations and kernels and provides useful options and features like a method for plotting, but it lacks a proper model selection tool. The ‘svm’ function in package ‘e1071’ includes a model selection tool: the ‘tune’ function (Karatzoglou et al., 2006)
```{r}
library(kernlab)
##
## Attaching package: 'kernlab'
## The following objects are masked from 'package:raster':
##
##     buffer, rotated
svm <- ksvm(pa ~ bio1+bio5+bio6+bio7+bio8+bio12+bio16+bio17, data=envtrain)

#svm <- ksvm(pa ~ ., data=envtrain)
esv <- evaluate(testpres, testbackg, svm)
esv
## class          : ModelEvaluation
## n presences    : 23
## n absences     : 200
## AUC            : 0.7576087
## cor            : 0.3738667
## max TPR+TNR at : 0.02857293
ps <- predict(predictors, svm, ext=ext)
par(mfrow=c(1,2))
plot(ps, main='Support Vector Machine')
plot(wrld_simpl, add=TRUE, border='dark grey')
tr <- threshold(esv, 'spec_sens')
plot(ps > tr, main='presence/absence')
plot(wrld_simpl, add=TRUE, border='dark grey')
points(pres_train, pch='+')
points(backg_train, pch='-', cex=0.25)
```
For evaluating SVM


```{r}

#library(caret)


# Make predictions on the test dataset
predictions <- predict(predictors, svm, ext=ext)

# Generate the confusion matrix
confusionMatrix <- confusionMatrix(predictions, envtest$pa)

# Print the confusion matrix
print(confusionMatrix)

# Calculate performance metrics
accuracy <- confusionMatrix$overall['Accuracy']
precision <- confusionMatrix$byClass['Precision']
recall <- confusionMatrix$byClass['Recall']
specificity <- confusionMatrix$byClass['Specificity']
F1_score <- 2 * (precision * recall) / (precision + recall)
AUC <- roc(envtest$pa, as.numeric(predictions))$auc

# Print performance metrics
cat("Accuracy:", accuracy, "\n")
cat("Precision:", precision, "\n")
cat("Recall (Sensitivity):", recall, "\n")
cat("Specificity:", specificity, "\n")
cat("F1 Score:", F1_score, "\n")
cat("AUC:", AUC, "\n")

```